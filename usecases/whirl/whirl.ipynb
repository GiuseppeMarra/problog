{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WHIRL in ProbLog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Februari 2015  \n",
    "[Wannes Meert](mailto:wannes.meert@cs.kuleuven.be), [Anton Dries](mailto:anton.dries@cs.kuleuven.be), DTAI Research Group, KU Leuven"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Cohen 2000b):\n",
    "\n",
    "> WHIRL is an “information representation language” that synergistically combines properties of logic-based and text-based representation systems. WHIRL is a subset of Datalog that has been extended by introducing an atomic type for textual entities, an atomic operation for computing textual similarity, and a “soft” semantics; that is, inferences in WHIRL are associated with numeric scores, and presented to the user in decreasing order by score. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Cohen, 2000a) W. W. Cohen. Whirl: A word-based information representation language. Artificial Intelligence, 118(1):163–196, 2000.\n",
    "\n",
    "(Cohen, 2000b) W. W. Cohen. Data integration using similarity joins and a word-based information representation language. ACM Transactions on Information Systems (TOIS), 18(3):288–321, 2000."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Differences between WHIRL and ProbLog\n",
    "\n",
    "### Recursion and negation\n",
    "\n",
    "WHIRL does not allow for recursion or negation. Additionally, only one `many/2` predicate is allowed in a query. These restrictions do not apply to Problog because it knows how to handle such situations (e.g. the inclusion-exclusion principle).\n",
    "\n",
    "### Search strategy\n",
    "\n",
    "Problog does not use a find-best-substitution approach like the WHIRL system that uses an A* search strategy. The default reasoning technique in Problog finds all proofs. But the optimizations present in WHIRL can be implemented in the Python part.\n",
    "\n",
    "### Storage\n",
    "\n",
    "A more efficient way of storing all the reviews is to preprocess all reviews and use compact vector representations in ProbLog. This is also how it is represented in Cohen (200a). For illustratieve purposes, in this example we use full strings in ProbLog."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we will be using movie reviews, listings and other information. The data is represented using Prolog facts:\n",
    "\n",
    "- `listing/3`: Movie theater listing\n",
    "- `review/2`: Movie review\n",
    "- `academy_award/1`: Category of oscars\n",
    "- `winner/3`: Which movie won wat category in what year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "listing('Roberts Theater Chatham', 'Brassed Off', '7:15 - 9:10').\r\n",
      "listing('Berkeley Cinema', 'Hercules', '2:00 - 4:15 - 7:30').\r\n",
      "listing('Sony Mountainside Theater', 'Men in Black', '7:40 - 8:40 - 9:30 - 10:10').\r\n",
      "\r\n",
      "review('Men in Black, 1997', '(***) One of the summer s biggest hits, this ... a comedy about space aliens with Will Smith ...').\r\n",
      "review('Face/Off, 1997',     '(**1/2) After a somewhat slow start, Cage and Travolta').\r\n",
      "review('Space Balls, 1987',  '(*1/2) While not one of Mel Brooks better efforts, this Star Wars spoof ... a comedy about space').\r\n",
      "review('Hercules',  'Animated Disney film').\r\n",
      "review('The Lord of the Rings: The Fellowship of the Ring, 2001', 'An epic fantasy film directed by Peter Jackson based on the first volume of J. R. R. Tolkien The Lord of the Rings. It is the first installment in the The Lord of the Rings film series, and was followed by The Two Towers (2002) and The Return of the King (2003), based on the second and third volumes of The Lord of the Rings.').\r\n",
      "\r\n",
      "academy_award('Best makeup').\r\n",
      "\r\n",
      "winner('Men in Black', 'Best makeup', 1997).\r\n",
      "winner('The Lord of the Rings: The Fellowship of the Ring', 'Best makeup', 2001).\r\n"
     ]
    }
   ],
   "source": [
    "!head -n 49 whirl.pl | tail -n 14"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similarity Metric and Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarity is expressed as $X \\sim Y$ in WHIRL and `similar(X,Y)` in our version. It has a score value associated it with it that in ProbLog will be expressed as a probability associated with a probabilistic fact.\n",
    "\n",
    "The $SCORE(B,\\theta)$ of an expression $B$ and substitution $\\theta$ is computed using this similarity.\n",
    "\n",
    "- if $B$ is a literal and a fact in the DB: $SCORE(B,\\theta) = s$ (the score, probability or weight of the fact)\n",
    "- if $B$ is a literal but not in the DB: $SCORE(B,\\theta) = 0$\n",
    "- if $B$ is a similarity literal $X \\sim Y$: $SCORE(B,\\theta) = SIM(\\vec{x}, \\vec{y})$, where $\\vec{x} = X\\theta$ and $\\vec{y} = Y\\theta$ and $\\theta$ a ground substitution.\n",
    "\n",
    "The similarity ($SIM$, $X \\sim Y$ or `similar(X,Y)`) between sentences and documents is computed using the TF-IDF metric (see `whirl.py` for the complete code).\n",
    "\n",
    "We use NLTK to translate a sentence into a list of stems:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk import word_tokenize\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "def tokenize(text):\n",
    "  return (stemmer.stem(token) for token in word_tokenize(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And Scikit-learn to compute the TF-IDF parameters and the similarity between sentences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['text', 'topic1', 'topic2']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.57973867,  0.81480247,  0.        ],\n",
       "       [ 0.57973867,  0.        ,  0.81480247]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "texts = ['Text topic1', 'And text topic2'] # In our setting, all the movie reviews are loaded\n",
    "tfidf = TfidfVectorizer(tokenizer=tokenize, stop_words='english')\n",
    "weights = tfidf.fit_transform(texts)\n",
    "\n",
    "def similarity(sentence1, sentence2):\n",
    "  return cosine_similarity(tfidf.transform(sentence1),tfidf.transform(sentence2))\n",
    "\n",
    "print(tfidf.get_feature_names())\n",
    "weights.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Python within ProbLog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python code can be run from ProbLog by including a Python file using `load_external/1` and calling a Python method using `call_external/2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t  similar('comedy Smith','Will Smith') : 0.77828292\n",
      "\tsimilar('comedy Smith','space Brooks') : 0\n",
      "\t similar('comedy Smith','space Smith') : 0.60572431\n"
     ]
    }
   ],
   "source": [
    "%%script problog-cli.py\n",
    ":- load_external('whirl.py').\n",
    "\n",
    "P::similar(X,Y) :-\n",
    "    call_external(similarity(X,Y), P),\n",
    "    P > 0.0.\n",
    "            \n",
    "query(similar('comedy Smith', 'space Smith')).\n",
    "query(similar('comedy Smith', 'space Brooks')).\n",
    "query(similar('comedy Smith', 'Will Smith'))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `fail/0` in the `similar/2` call is to instruct ProbLog not to keep track of two entities that are completely unrelated (instead of performing computations with probability 0.0).\n",
    "\n",
    "The results can be interpreted as follows:\n",
    "\n",
    "- 'comedy Smith' and 'Will Smith' has the highest probability because there is only one movie that is a comedy with Will Smith\n",
    "- 'comedy Smith' and 'space Smith' is a bit lower because there are two space comedies\n",
    "- 'comedy Smith' and 'space Brooks' is zero because there is no overlap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can adapt the `similar/2` predicate to use a more efficient search strategy and only unify if the two terms are very similar. If `similar\\2` fails, the atom is ignored and the combination of the two terms is not further explored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t  similar('comedy Smith','Will Smith') : 0.77828292\n",
      "\tsimilar('comedy Smith','space Brooks') : 0\n",
      "\t similar('comedy Smith','space Smith') : 0\n"
     ]
    }
   ],
   "source": [
    "%%script problog-cli.py\n",
    ":- load_external('whirl.py').\n",
    "\n",
    "P::similar(X,Y) :-\n",
    "    call_external(similarity(X,Y), P),\n",
    "    P > 0.7. % Only keep likely matches\n",
    "            \n",
    "query(similar('comedy Smith', 'space Smith')).\n",
    "query(similar('comedy Smith', 'space Brooks')).\n",
    "query(similar('comedy Smith', 'Will Smith'))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An optimisation proposed in Cohen (2000a) that is possible in the Python part is to build an (inverted) index of similar documents instead of trying all combinations:\n",
    "\n",
    "> Consider x􏲄, corresponding to the document \"Armadillos, Inc\". Due to the frequent term \"Inc\", there will be many documents Y that have nonzero similarity to x􏲄, and it will be expensive to retrieve all of these documents Y and compute their similarity to x􏲄. One way of avoiding this expense is to start by retrieving a small number of documents Y that are likely to be highly similar to x􏲄. In this case, one might use an index to find all Y's that contain the rare term \"Armadillos\". Since \"Armadillos\" is rare, this step will be inexpensive, and the Y's retrieved in this step must be somewhat similar to x􏲄."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conjunctive Queries\n",
    "\n",
    "The score of a conjunctive query $B_1 \\lor \\dots \\lor B_k$ is\n",
    "\n",
    "\\begin{equation*}\n",
    "SCORE(B_1 \\land \\dots \\land B_k, \\theta) = 1 - \\prod_{i=1}^{k}SCORE(B_i,\\theta)\n",
    "\\end{equation*}\n",
    "\n",
    "with $\\theta$ the ground unification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1\n",
    "\n",
    "Find reviews about comedies with space aliens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%script --out result problog-cli.py\n",
    ":- consult(whirl).\n",
    "\n",
    "q1(Movie, Review) :- review(Movie, Review),\n",
    "                     similar(Review, 'comedy with space aliens').\n",
    "query(q1(X,Y))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr><td>\tq1('Men in Black, 1997','(***) One of the summer s biggest hits, this ... a comedy about space aliens with Will Smith ...') <td>0.53799496<tr><td>\t q1('Space Balls, 1987','(*1/2) While not one of Mel Brooks better efforts, this Star Wars spoof ... a comedy about space') <td>0.27688516</table>"
      ],
      "text/plain": [
       "<__main__.problogResult at 0x10b429080>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "problogResult(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2\n",
    "\n",
    "Soft database join to see times and reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%script --out result problog-cli.py\n",
    ":- consult(whirl).\n",
    "\n",
    "q2(Cinema,Movie1,Times,Review) :- listing(Cinema, Movie1, Times),\n",
    "                                  review(Movie2, Review),\n",
    "                                  similar(Movie1,Movie2).\n",
    "query(q2(C,M,T,R))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr><td>\t                                                                                                  q2('Berkeley Cinema','Hercules','2:00 - 4:15 - 7:30','Animated Disney film') <td>1.0<tr><td>\tq2('Sony Mountainside Theater','Men in Black','7:40 - 8:40 - 9:30 - 10:10','(***) One of the summer s biggest hits, this ... a comedy about space aliens with Will Smith ...') <td>0.86859437</table>"
      ],
      "text/plain": [
       "<__main__.problogResult at 0x110226588>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "problogResult(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3\n",
    "\n",
    "Database join to see times and reviews. Whill be empty if no exactly matching movie titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tq3('Berkeley Cinema','Hercules','2:00 - 4:15 - 7:30','Animated Disney film') : 1\n"
     ]
    }
   ],
   "source": [
    "%%script problog-cli.py\n",
    ":- consult(whirl).\n",
    "\n",
    "q3(Cinema,Movie,Times,Review) :- listing(Cinema,Movie,Times),\n",
    "                                 review(Movie,Review).\n",
    "query(q3(C,M,T,R))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q4\n",
    "\n",
    "See where the latest science fiction comedy is playing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t q4('Brassed Off') : 0\n",
      "\t    q4('Hercules') : 0\n",
      "\tq4('Men in Black') : 0.46729939\n"
     ]
    }
   ],
   "source": [
    "%%script problog-cli.py\n",
    ":- consult(whirl).\n",
    "\n",
    "q4(Movie1) :- listing(Cinema, Movie1, Times), review(Movie2, Review),\n",
    "              similar(Movie1, Movie2),\n",
    "              similar(Review,\"comedy with space aliens\").\n",
    "query(q4(M))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Disjunctive Queries\n",
    "\n",
    "The probability of a disjunctive query is\n",
    "\n",
    "\\begin{equation*}\n",
    "SCORE(a, \\theta) = 1 - \\prod_{<\\theta,Body_i> \\in SUPPORT(a)}(1-SCORE(Body_i,\\theta))\n",
    "\\end{equation*}\n",
    "\n",
    "with SUPPORT for literal $a = v(a_1,\\dots,a_k)$ is the set of pairs $<\\theta,Body_i>$ for which\n",
    "\n",
    "- $v(X_1,\\dots,X_k)$ :- $Body_i.$ is a rule\n",
    "- $\\exists \\theta: v(X_1,\\dots,X_k)\\theta = a$\n",
    "- $Body_i\\theta$ is ground, and $SCORE(Body_i,\\theta) > 0$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q4 (disjunctive)\n",
    "\n",
    "Disjunctive version of Q4. Finds cinemas that are playing either a science fiction comedy or an animated film produced by Disney"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t          q4a('Berkeley Cinema') : 1\n",
      "\t  q4a('Roberts Theater Chatham') : 0\n",
      "\tq4a('Sony Mountainside Theater') : 0.46729939\n"
     ]
    }
   ],
   "source": [
    "%%script problog-cli.py\n",
    ":- consult(whirl).\n",
    "\n",
    "view1(Cinema) :- listing(Cinema, Movie1, Times), \n",
    "                 review(Movie2, Review),\n",
    "                 similar(Movie1, Movie2),\n",
    "                 similar(Review, \"comedy with space aliens\").\n",
    "view1(Cinema) :- listing(Cinema, Movie1, Times),\n",
    "                 review(Movie2, Review),\n",
    "                 similar(Movie1, Movie2),\n",
    "                 similar(Review, \"animated Walt Disney film\").\n",
    "q4a(Cinema) :- view1(Cinema).\n",
    "query(q4a(C))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Soft Universal Quantification\n",
    "\n",
    "Soft universal quantification is expressed as `many(Template, Test)` and defined as the weighted average of the scores where the test succeeds for the given template:\n",
    "\n",
    "\\begin{equation*}\n",
    "SCORE(many(p(Y_1, \\dots, Y_k), Test, \\theta) = \\sum_{<s,a_1,\\dots,a_k> \\in P} \\frac{s}{S}\\cdot SCORE\\left(Test, (\\theta \\cup {Y_1=a_1, \\dots, Y_k=a_k})\\right)\n",
    "\\end{equation*}\n",
    "\n",
    "with $P$ the set of all tuples $<s,a_1,\\dots,a_k>$ such that $p(a_1,\\dots,a_k)$ in the DB with score $s$. and $S = \\sum_{<s,a_1,\\dots,a_k>\\in P}s$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q5 (deterministic)\n",
    "\n",
    "Movie with Will Smith that won an award without fuzzy matching will find no results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during grounding: No clauses found for 'winner/2' at position 5:35.\n"
     ]
    }
   ],
   "source": [
    "%%script problog-cli.py\n",
    ":- consult(whirl).\n",
    "\n",
    "q5a(Movie, Cat) :- review(Movie ,Review),\n",
    "              similar(Review, \"Will Smith\"),\n",
    "              academy_award(Cat), winner(Movie2, Cat),\n",
    "              similar(Movie, Movie2).\n",
    "query(q5a(M,C))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q5\n",
    "\n",
    "Movie that is currently playing and has *many* academy awards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t q5('Brassed Off') : 0\n",
      "\t    q5('Hercules') : 0\n",
      "\tq5('Men in Black') : 0.5\n"
     ]
    }
   ],
   "source": [
    "%%script problog-cli.py\n",
    ":- consult(whirl).\n",
    "\n",
    "q5(M) :-\n",
    "    listing(_,M,_),\n",
    "    % many(Template, Test) as findall(Test, Template, L)\n",
    "    findall(winner(M,C,Y), (academy_award(C),winner(_,C,Y)), L),\n",
    "    many_int_prob(L).\n",
    "query(q5(M))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `many` predicate present in WHIRL can be implemented in ProbLog using `findall` and a custom predicate to count the weighted average:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%script problog-cli.py\n",
    "\n",
    "many_int([], P, N, 0) :- T is P+N, T = 0.\n",
    "many_int([], P, N, S) :- T is P+N, T > 0, S is P/T.\n",
    "many_int([H|T], PA, NA, S) :-\n",
    "    (  call(H), PAN is PA + 1, NAN is NA;      % Test: true\n",
    "     \\+call(H), PAN is PA,     NAN is NA + 1), % Test: false\n",
    "    many_int(T, PAN, NAN, S).\n",
    "\n",
    "S::many_int_prob(L) :- many_int(L, 0, 0, S).\n",
    "\n",
    "many(Template, Test) :-\n",
    "    findall(Test, Template, L),\n",
    "    many_int_prob(L)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://dtai.cs.kuleuven.be/problog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Document setup*: This document can be run as an IPython notebook. You can ignore the next code block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class problogResult:\n",
    "    def __init__(self,string):\n",
    "        self.list = [s.rsplit(':',1) for s in string.split('\\n') if s != '']\n",
    "        for t in self.list: t[1] = float(t[1])\n",
    "        self.list.sort(key=lambda x:x[1], reverse=True)\n",
    "    def _repr_html_(self):\n",
    "        return '<table>'+''.join(['<tr>{}'.format(''.join(['<td>{}'.format(cell) for cell in row])) for row in self.list])+'</table>'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
